{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e9875c-2829-466a-baa5-e9aeba5d7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f57d8911-fb40-4d54-81fd-68d17e2a911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"heart_disease_2000_rows.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"Heart_Disease_Presence\", axis=1)\n",
    "y = df[\"Heart_Disease_Presence\"]\n",
    "\n",
    "# Remove duplicates for test set\n",
    "df_expanded_unique = df.drop_duplicates()\n",
    "print(df_expanded_unique.shape)\n",
    "\n",
    "# Split dataset (test set stays original, unique)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "# SCALING\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Encode Categorical Features & Scale Numeric Features\n",
    "categorical_features = [\"Sex\", \"Chest_Pain_Type\", \"Fasting_Blood_Sugar\", \n",
    "                        \"Resting_ECG\", \"Exercise_Angina\", \"ST_Slope\", \n",
    "                        \"Major_Vessels\", \"Thalassemia\"]\n",
    "\n",
    "numeric_features = [\"Age\", \"Resting_Blood_Pressure\", \"Serum_Cholesterol\", \n",
    "                    \"Max_Heart_Rate\", \"ST_Depression\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c707f41-12e2-48d6-a243-694d2a21e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 14)\n",
      "Heart_Disease_Presence\n",
      "1    0.75\n",
      "0    0.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate classes\n",
    "df_1 = df[df[\"Heart_Disease_Presence\"] == 1]\n",
    "df_0 = df[df[\"Heart_Disease_Presence\"] == 0]\n",
    "\n",
    "# Desired counts\n",
    "n_1 = 1500   # 75%\n",
    "n_0 = 500    # 25%\n",
    "\n",
    "# Resample with replacement\n",
    "df_1_resampled = df_1.sample(n=n_1, replace=True, random_state=42)\n",
    "df_0_resampled = df_0.sample(n=n_0, replace=True, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "df_expanded = pd.concat([df_1_resampled, df_0_resampled]) \\\n",
    "                 .sample(frac=1, random_state=42) \\\n",
    "                 .reset_index(drop=True)\n",
    "\n",
    "print(df_expanded.shape)\n",
    "print(df_expanded[\"Heart_Disease_Presence\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da8d416b-3ba2-4efd-bf45-6ef720691eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64       178\n",
      "           1       0.70      0.95      0.81       222\n",
      "\n",
      "    accuracy                           0.75       400\n",
      "   macro avg       0.79      0.72      0.72       400\n",
      "weighted avg       0.78      0.75      0.73       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER PC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a322a287-b045-4fba-87ca-98da703c4c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "#Model 1: Logistic Regression \n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(\n",
    "        C=0.01,       \n",
    "        max_iter=200\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5acee01-28b9-4005-9ecd-92225cd03d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "#Model 2: Logistic Regression + GridSearchCV\n",
    "param_grid = {\n",
    "    \"lr__C\": [0.01, 0.1, 1, 10],\n",
    "    \"lr__penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    lr_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "grid_lr.fit(X_train, y_train)\n",
    "y_pred_grid = grid_lr.predict(X_test)\n",
    "acc_grid = accuracy_score(y_test, y_pred_grid)\n",
    "print(\"Accuracy:\",acc_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1172b308-4e76-4708-bb71-051109b95598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "#Model 3 â€“ Gradient Descent (Logistic Regression with SGD)\n",
    "sgd_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sgd\", SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        penalty=\"l2\",\n",
    "        alpha=0.0001,\n",
    "        max_iter=2000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sgd = sgd_pipeline.predict(X_test)\n",
    "acc_gd = accuracy_score(y_test, y_pred_sgd)\n",
    "print(\"Accuracy:\",acc_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b86cc47-34d1-403a-8537-8c37f599bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Model 4: Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=300, max_depth=6, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy:\", acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6f3d38d-34f4-4fcf-946a-8bb8f62c5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Accuracy\n",
      "0    Logistic Regression    0.8225\n",
      "1  Logistic + GridSearch    0.8450\n",
      "2       Gradient Descent    0.8475\n",
      "3          Random Forest    0.9700\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Logistic + GridSearch\",\"Gradient Descent\", \"Random Forest\"],\n",
    "    \"Accuracy\": [acc_lr, acc_grid, acc_gd, acc_rf]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cfda806-b8c5-40dd-9f0f-22bf95c1b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    lr,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a23eb27-5ce0-43b1-9fc4-dbfc22410e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       178\n",
      "           1       0.84      0.89      0.86       222\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.85      0.84      0.84       400\n",
      "weighted avg       0.85      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db7b7934-e132-4646-bf33-79f1527eb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[141  37]\n",
      " [ 25 197]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47092244-bcd1-4240-a33a-6598974c8fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.36683655275078436\n"
     ]
    }
   ],
   "source": [
    "y_prob = best_model.predict_proba(X_test)\n",
    "loss = log_loss(y_test, y_prob)\n",
    "\n",
    "print(\"Log Loss:\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
